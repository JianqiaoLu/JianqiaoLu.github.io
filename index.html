<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Jianqiao Lu | 陆剑桥</title>
  <meta name="description" content="Jianqiao Lu (陆剑桥) — Research Engineer at ByteDance Seed Foundation Model. Focus: scaling & efficiency, long-context training/inference." />
  <style>
    :root {
      --text: #111;
      --muted: #555;
      --border: #e6e6e6;
      --link: #0b5fff;
      --bg: #ffffff;
      --chip: #f5f7ff;
    }
    html, body { background: var(--bg); color: var(--text); }
    body {
      margin: 0;
      font-family: ui-serif, "Palatino Linotype", "Book Antiqua", Palatino, Georgia, serif;
      line-height: 1.65;
      -webkit-font-smoothing: antialiased;
      text-rendering: optimizeLegibility;
    }
    a { color: var(--link); text-decoration: none; }
    a:hover { text-decoration: underline; }

    .container {
      max-width: 980px;
      margin: 0 auto;
      padding: 28px 18px 48px;
    }

    header {
      display: flex;
      gap: 18px;
      align-items: center;
      border-bottom: 1px solid var(--border);
      padding-bottom: 18px;
      margin-bottom: 20px;
    }

    .avatar {
      width: 108px;
      height: 108px;
      border-radius: 999px;
      overflow: hidden;
      flex: 0 0 auto;
      border: 1px solid var(--border);
      box-shadow: 0 6px 18px rgba(0,0,0,0.08);
    }
    .avatar img {
      width: 100%;
      height: 100%;
      object-fit: cover;
      display: block;
    }

    .title h1 {
      margin: 0;
      font-size: 34px;
      line-height: 1.2;
      letter-spacing: 0.2px;
    }
    .title .subtitle {
      margin-top: 6px;
      color: var(--muted);
      font-size: 16px;
    }

    .chips {
      margin-top: 10px;
      display: flex;
      flex-wrap: wrap;
      gap: 8px;
    }
    .chip {
      display: inline-block;
      padding: 5px 10px;
      border: 1px solid var(--border);
      background: var(--chip);
      border-radius: 999px;
      font-size: 13px;
      color: var(--muted);
    }

    nav {
      margin-top: 10px;
      display: flex;
      flex-wrap: wrap;
      gap: 10px 14px;
      font-size: 14px;
      color: var(--muted);
    }
    nav a { white-space: nowrap; }

    section { margin-top: 22px; }
    section h2 {
      margin: 0 0 10px;
      font-size: 22px;
    }
    section h3 {
      margin: 14px 0 6px;
      font-size: 18px;
      color: var(--text);
    }

    .note {
      color: var(--muted);
      font-size: 14px;
      border-left: 3px solid var(--border);
      padding: 6px 10px;
      margin: 10px 0 0;
    }

    /* legacy lists from the old page */
    ul.circle {
      margin: 10px 0 0 22px;
      padding: 0;
    }
    ul.circle li {
      margin: 8px 0;
    }

    footer {
      margin-top: 30px;
      padding-top: 14px;
      border-top: 1px solid var(--border);
      color: var(--muted);
      font-size: 14px;
      display: flex;
      justify-content: space-between;
      gap: 10px;
      flex-wrap: wrap;
    }

    @media (max-width: 640px) {
      header { align-items: flex-start; }
      .avatar { width: 92px; height: 92px; }
      .title h1 { font-size: 28px; }
    }
  </style>
</head>
<body>
  <div class="container">

    <header>
      <div class="avatar-col">
        <div class="avatar">
          <img src="compressed_selfie.png" alt="Jianqiao Lu portrait" />
        </div>
        <p class="motto">Better wrong than idle.</p>
      </div>
      <div class="title">
        <h1>Jianqiao Lu &nbsp; 陆剑桥</h1>
        <div class="subtitle">
          ByteDance Seed Foundation Model · Scaling & Efficiency · Long Context
        </div>

        <nav>
          <a href="mailto:tjlujianqiao@gmail.com">Email</a>
          <a href="trival.html">Trivia</a>
          <a href="https://scholar.google.com/citations?user=uIW6d6AAAAAJ&hl=zh-CN" target="_blank" rel="noopener noreferrer">
            Google Scholar
          </a>
          <a href="https://github.com/rookie-joe/" target="_blank" rel="noopener noreferrer">GitHub</a>
          <a href="CV_Jianqiao_Lu.pdf" target="_blank" rel="noopener noreferrer">CV</a>
        </nav>
        

        <div class="chips">
          <span class="chip">Now: ByteDance Seed</span>
          <span class="chip">Previously: PhD @ HKU</span>
          <span class="chip">Focus: Training/Inference Efficiency</span>
        </div>
      </div>
    </header>

    <section id="about">
      <h2>About</h2>
      <p>
        I am a <strong>Research Engineer</strong> at <strong>ByteDance Seed Foundation Model</strong>, contributing to large-scale
        foundation model pretraining. My current focus is <strong>scaling and efficiency</strong>—especially training stability,
        throughput/cost, and <strong>long-context</strong> training &amp; inference efficiency.
      </p>

      <h3>Interests</h3>
      <ul class="circle">
        <li><strong>Scaling &amp; efficiency:</strong> training stability, throughput, and cost.</li>
        <li><strong>Long context:</strong> efficient training and inference/prefill for long sequences.</li>
        <li><strong>Systems &amp; architecture:</strong> practical optimizations that improve stability and efficiency at scale.</li>

      </ul>


      <h3>Previously</h3>
      <p>
        I was a PhD student supervised by
        <a href="https://i.cs.hku.hk/~zhiyi/index.html">Prof. Zhiyi Huang</a>
        at The University of Hong Kong (HKU).
      </p>
</section>

    <section id="contact">
      <h2>Contact</h2>
      <ul class="circle">
        <li><b>Email:</b> <a href="mailto:tjlujianqiao@gmail.com">tjlujianqiao@gmail.com</a></li>
      </ul>
    </section>

    <section id="collaboration">
      <h2>Collaboration</h2>
      <div>
        <br>&nbsp;&nbsp; I feel fortunate and empowered to work closely with <a href="https://cartus.github.io/">Dr. Zhijiang Guo</a>, Dr. Zhengying Liu, <a href="https://eleanor-h.github.io/">Dr. Yinya Huang</a>, and <a href="https://yingjia.one/">Yingjia Wan</a>. Our collaboration focuses on advancing topics in both formal and informal mathematical reasoning for Large Language Models, driving innovation and excellence in these fields.
      </div>
    </section>

    <section id="news">
      <h2>News</h2>

          <ul class="circle">
            <li>
                <b>Sep. 2024:&nbsp;</b>  (First Author)
                <i>
                    <a href="https://arxiv.org/abs/2405.16802">
                      "AutoPSV: Automated Process-Supervised Verifier"
                    </a>
                </i>, was accepted to <b>NeurIPS 2024.</b>
            </li>
          </ul>

          <ul class="circle">
            <li>
                <b>Sep. 2024:&nbsp;</b> 
                <i>
                    <a href="https://arxiv.org/abs/2405.14414">
                      "Proving Theorems Recursively"
                    </a>
                </i>, was accepted to <b>NeurIPS 2024.</b>
            </li>
          </ul>

          <ul class="circle">
            <li>
                <b>Sep. 2024:&nbsp;</b> 
                <i>
                    <a href="https://arxiv.org/abs/2406.13975">
                      "Mr.Bean: A Comprehensive Meta-Reasoning Benchmark for Analyzing Large Language Models"
                    </a>
                </i>, was accepted to <b>NeurIPS 2024.</b>
            </li>
          </ul>

          <ul class="circle">
            <li>
                <b>Sep. 2024:&nbsp;</b> 
                <i>
                    <a href="https://arxiv.org/abs/2410.06868">
                      "Online Matching Meets Sampling Without Replacement"
                    </a>
                </i>, was accepted to <b>WINE 2024.</b>
            </li>
          </ul>

        <ul class="circle">
          <li>
              <b>Sep. 2024:&nbsp;</b> 
              <i>
                  <a href="https://arxiv.org/abs/2406.14408">
                    "FVEL: Interactive Formal Verification Environment with Large Language Models via Theorem Proving"
                  </a>
              </i>, was accepted to <b>NeurIPS 2024 (Datasets and Benchmarks Track).</b>
              <a href="https://fveler.github.io/" target="_blank" title="Project" style="background-color: white; color: black; padding: 5px;">Project</a> 
          </li>
        </ul>

          <ul class="circle">
            <li>
                <b>May 2024:&nbsp;</b> 
                <i>
                    <a href="https://arxiv.org/pdf/2401.17167.pdf">
                        "Planning, Creation, Usage: Benchmarking LLMs for Comprehensive Tool Utilization in Real-World Complex Scenarios"
                    </a>
                </i>, was accepted to <b>ACL 2024.</b>
                <!-- Code Repository Link -->
                <a href="https://github.com/JoeYing1019/UltraTool" target="_blank" title="Code" style="background-color: white; color: black; padding: 5px;">Code</a> 
            </li>
          </ul>

          <ul class="circle">
            <li>
                <b>Jan 2024:&nbsp;</b> (First Author)
                <i>
                    <a href="https://arxiv.org/abs/2310.05374">
                        "Improving End-to-End Speech Processing by Efficient Text Data Utilization with Latent Synthesis"
                    </a>
                </i>, was accepted to <b>EMNLP 2023.</b>
            </li>
          </ul>
        <br>


    </section>

    <section id="preprint">
      <h2>Preprint</h2>
        <h3>Large Language Models</h3>
        <ul class="circle">                
            <li><b>Oct 2023:&nbsp;</b>(First Author) <i><a href="https://arxiv.org/abs/2310.00533">"SELF: Self-Evolution with Language Feedback"</a></i>, was released on arXiv. (A self-evolution framework for autonomous self-improvement of large language models through self-feedback and iterative self-refinement.) </li>
        </ul>

        <ul class="circle">                
            <li><b>Jan 2024:&nbsp;</b>(First Author) <i><a href="https://arxiv.org/abs/2401.15670">"YODA: Teacher-Student Progressive Learning for Language Models"</a></i>, was released on arXiv. (A learning framework that mimics human progressive learning to enhance language model fine-tuning.) </li>
        </ul>

        <ul class="circle">                
            <li><b>Jan 2024:&nbsp;</b>(Equal Contribution) <i><a href="https://arxiv.org/abs/2405.11430">"MHPP: Exploring the Capabilities and Limitations of Language Models Beyond Basic Code Generation"</a></i>, was released on arXiv. (A benchmark to rigorously assess LLMs' code generation abilities, revealing significant gaps in existing benchmarks and providing new insights into LLMs' strengths and weaknesses.) </li>
        </ul>




        <ul class="circle">                
            <li><b>May 2024:&nbsp;</b>(First Author) <i>  <a href="https://arxiv.org/abs/2406.01940">"Process-Driven Autoformalization in Lean 4" </a></i>, was released on arXiv.  </li>
        </ul>


        <ul class="circle">                
            <li><b>May 2024:&nbsp;</b> <i> "DialogBench: An Interactive Benchmark for Humanized Dialogue Agent" </i>, will be soon released on arXiv.  </li>
        </ul>



        <ul class="circle">                
            <li><b>June 2024:&nbsp;</b> (First Author) <i>   <a href="https://arxiv.org/abs/2410.10135">"FormalAlign: Automated Alignment Evaluation in Autoformalization" </a> </i> was released on arXiv. </li>
        </ul>






        <br>


    </section>

    <footer>
      <div>© 2026 Jianqiao Lu</div>
      <div>
        <a href="#about">About</a> ·
        <a href="#news">News</a> ·
        <a href="#preprint">Preprint</a>
      </div>
    </footer>

  </div>
</body>
</html>
